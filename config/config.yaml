# Default configuration for forex prediction experiments

# Data configuration (preparation phase)
data:
  raw: data/raw/dukascopy-usdjpy-tick-2020-01-01-2024-12-31.csv

# Resampling configuration
resampling:
  type: time # 'time' or 'dollar'
  minutes: 1 # For time-based resampling
  threshold: 421558000000 # For dollar bar resampling
  symbol: "USDJPY"
  date_range:
    start_date: "20210101" # Format: YYYYMMDD
    end_date: "20241231" # Format: YYYYMMDD
  output:
    dir: data/resampled
    prefix: bars

events:
  # Event sampling configuration
  type: CUSUM # 'cusum' or 'volatility'
  threshold: 2.52e-04 # CUSUM threshold for event detection

# Labeling configuration
labeling:
  # CUSUM event detection
  volatility_method: intraday # 'intraday' or 'atr'
  volatility_window: 60
  volatility_span: 60
  vol_multiplier: 1.0 # CUSUM threshold = vol_multiplier * median_volatility

  # Triple barrier parameters
  pt_sl: [1.0, 1.0] # [profit_taking_multiplier, stop_loss_multiplier]
  min_ret: 0.0 # Minimum return threshold to filter events
  time_barrier_hours: 2.0 # Maximum holding period in hours

  # Filtering options
  intraday_only: true # Only keep events that start and end on same day

  # Processing options
  num_threads: 8

  # Output settings
  output:
    dir: data/labels

# Preprocessing configuration
preprocessing:
  # Feature engineering settings
  features:
    add_returns: true
    add_technical_indicators: true
    add_time_features: true

    # Technical indicator settings
    technical_indicators:
      ema_windows: [5, 20, 50, 100]
      atr_windows: [14, 20, 50]
      adx_windows: [14]
      bollinger_bands:
        window: 20
        window_dev: 2
      donchian_channel:
        window: 20
      stochastic:
        window: 14
        smooth_window: 3
      rsi:
        window: 14
      macd:
        window_slow: 26
        window_fast: 12
        window_sign: 9

    # Return feature settings
    return_features:
      rolling_mean_windows: [5, 10, 15, 20]
      log_volume: true

  # Normalization settings
  normalization:
    standard_scaler_features:
      - close_log_return
      - log_volume
      - spread
      - ret_mean_5
      - ret_mean_10
      - ret_mean_15
      - ret_mean_20
      - ema5
      - ema5_slope
      - ema20
      - ema20_slope
      - ema100
      - ema100_slope
      - atr14
      - atr20
      - atr50
      - vol_adj_return
      - close_to_atr
      - bb_upper
      - bb_lower
      - bb_mavg
      - bb_width
      - bb_position
      - donchian_upper
      - donchian_lower
      - donchian_mid
      - donchian_width
      - stoch_k
      - stoch_d
      - macd
      - macd_signal
      - macd_diff

    minmax_scaler_features:
      - rsi14
      - adx14
      - plus_di14
      - minus_di14

  # Output settings
  output:
    save_processed: true
    save_normalized: true
    save_scalers: true

# Model configuration
model:
  type: simple_transformer # 'simple_transformer', 't2v_transformer', 'gru', 'lstm'
  
  # Data configuration
  sequence_length: 120
  features: 
    - hour_cos
    - dow_cos
    - dom_cos
    - month_cos
    - close_log_return
    - ret_mean_5
    - ret_mean_10
    - log_volume
    - ema5_slope
    - ema20_slope
    - ema100_slope
    - atr20
    - vol_adj_return
    - close_to_atr
    - macd_diff
    - bb_width
    - bb_position
    - donchian_width
  target_col: bin_class
  
  # Model architecture hyperparameters
  transformer:
    d_model: 64
    nhead: 4
    num_layers: 2
    dim_feedforward: 256
    dropout: 0.3
    label_smoothing: 0.0
    pool: mean # 'mean' or 'last'
  
  gru:
    hidden_size: 64
    num_layers: 2
    dropout: 0.2
    bidirectional: false
  
  lstm:
    hidden_size: 64
    num_layers: 2
    dropout: 0.2
    bidirectional: false
  
  t2v_transformer:
    d_model: 64
    nhead: 4
    num_layers: 2
    dim_feedforward: 256
    dropout: 0.3
    label_smoothing: 0.0
    pool: mean
    
  output_size: 3

# Training configuration
training:
  epochs: 100
  batch_size: 256
  balanced_sampling: true
  
  # Optimizer hyperparameters
  optimizer:
    type: adamw # 'adam', 'adamw', 'sgd', 'rmsprop'
    learning_rate: 0.0003
    weight_decay: 0.0001
  
  # Learning rate scheduler
  scheduler:
    type: step # 'step', 'plateau', 'cosine', 'onecycle', or null
    step_lr:
      step_size: 10
      gamma: 0.5
    plateau_lr:
      patience: 5
      factor: 0.5
      min_lr: 1e-7
    cosine_lr:
      T_max: 100
      eta_min: 1e-7
    onecycle_lr:
      max_lr: 0.001
      pct_start: 0.3
  
  # Regularization
  gradient_clipping: 1.0
  
  # Early stopping
  early_stopping:
    patience: 12
    monitor: val_loss
    mode: min
    min_delta: 0.001

# Output configuration
output:
  dir: outputs
  model_filename: usdjpy_model.pt

logging:
  dir: logs/usdjpy_runs
  tensorboard: true
  log_interval: 5
  save_checkpoints: true
  checkpoint_interval: 10

hardware:
  cuda: true
  num_workers: 1
  pin_memory: true # Accelerates data transfer to GPU
  mixed_precision: true
