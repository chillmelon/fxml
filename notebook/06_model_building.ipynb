{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dd9993c-0ca7-47b6-a0b4-c045bb19421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "178f3e04-07b4-4131-affa-64fde8c27ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightning as L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd652e3-ebaf-412c-af38-f49020d8eb25",
   "metadata": {},
   "source": [
    "## Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f39f3f72-41cc-41bc-8367-e552719897ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from dataset.dataset import ForexDataset\n",
    "\n",
    "class ForexDataModule(L.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        IDs: list,\n",
    "        sequence_length: int,\n",
    "        horizon: int,\n",
    "        features: list,\n",
    "        target: list,\n",
    "        batch_size: int = 64,\n",
    "        num_workers: int = 0,\n",
    "        val_split: float = 0.2,\n",
    "        shuffle: bool = True,\n",
    "        random_state: int = 42\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.IDs = IDs\n",
    "        self.sequence_length = sequence_length\n",
    "        self.horizon = horizon\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.val_split = val_split\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        train_idx, val_idx = train_test_split(\n",
    "            self.IDs,\n",
    "            test_size=self.val_split,\n",
    "            shuffle=self.shuffle,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "\n",
    "        self.train_dataset = ForexDataset(\n",
    "            self.data, train_idx, self.sequence_length, self.horizon, self.features, self.target\n",
    "        )\n",
    "\n",
    "        self.val_dataset = ForexDataset(\n",
    "            self.data, val_idx, self.sequence_length, self.horizon, self.features, self.target\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090c331a-8cee-46a1-9fa5-2d1f298ac2c1",
   "metadata": {},
   "source": [
    "# GRU classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fa4ba8-ce9d-43b6-adeb-910f66a8f391",
   "metadata": {},
   "source": [
    "We've tried different criterion.\n",
    "    a. softmax + mse\n",
    "    b. raw logits + cross entropy\n",
    "We found that cross entropy performs better when using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd35020a-5543-4710-a54b-50b6649c433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import lightning as L\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, n_features, output_size, n_hidden, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=n_features,\n",
    "            hidden_size=n_hidden,\n",
    "            num_layers=n_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.linear = nn.Linear(n_hidden, output_size) # ouptput logits\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        self.gru.flatten_parameters()\n",
    "        _, hidden = self.gru(x)\n",
    "        logits = self.linear(hidden[-1])\n",
    "        return logits\n",
    "\n",
    "\n",
    "class GRUModule(L.LightningModule):\n",
    "    def __init__(self, n_features=1, output_size=1, n_hidden=64, n_layers=2, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = GRUModel(\n",
    "            n_features=self.hparams.n_features,\n",
    "            output_size=self.hparams.output_size,\n",
    "            n_hidden=self.hparams.n_hidden,\n",
    "            n_layers=self.hparams.n_layers,\n",
    "            dropout=self.hparams.dropout,\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.test_accuracy = MulticlassAccuracy(num_classes=output_size)\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        output = self.model(x)\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            labels = labels.squeeze().long()\n",
    "            loss = self.criterion(output, labels)\n",
    "        return loss, output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, _ = batch\n",
    "        loss, out = self(x, y)\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, logger=True)\n",
    "        return {\n",
    "            'loss': loss\n",
    "        }\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, _ = batch\n",
    "        loss, out = self(x, y)\n",
    "\n",
    "        self.log('val_loss', loss, prog_bar=True, logger=True)\n",
    "        return {\n",
    "            'loss': loss\n",
    "        }\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, _ = batch\n",
    "        loss, out = self(x, y)\n",
    "\n",
    "        y = y.squeeze().long()\n",
    "        preds = torch.argmax(out, dim=1)\n",
    "        acc = self.test_accuracy(preds, y)\n",
    "\n",
    "        self.log('test_loss', loss, prog_bar=True, logger=True)\n",
    "        self.log('test_acc', acc, prog_bar=True, logger=True)\n",
    "        return {'loss': loss, 'acc': acc}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d794773-edea-49cd-afcd-bb072229ac63",
   "metadata": {},
   "source": [
    "Now we've defined all the classes we need for the training.\n",
    "The following steps will use these to train a classification model to predict future movement of USDJPY close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d6cfdeb-6390-4c01-871f-d0a4cbc02ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PKL_PATH = \"../data/processed/usdjpy-h1-bar-2019-01-01-2025-05-12_processed.pkl\"\n",
    "SEQUENCE_LENGTH=30\n",
    "HORIZON=1 # The next nth timeframe to predict\n",
    "STRIDE=5 # Non-overlapping timeframe\n",
    "FEATURES_COLS = ['close_log_return_scaled']\n",
    "TARGET_COLS = ['train_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe1d993-f830-4d42-ace9-4a3c4fa75591",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25c72791-c104-4e47-8e46-ae2aeaaf4ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "568c5d3a-873c-4a97-9c69-d1023d02e97c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>time</th>\n",
       "      <th>log_volume</th>\n",
       "      <th>log_volume_scaled</th>\n",
       "      <th>time_group</th>\n",
       "      <th>close_delta</th>\n",
       "      <th>close_return</th>\n",
       "      <th>close_log_return</th>\n",
       "      <th>close_log_return_scaled</th>\n",
       "      <th>ret_mean_5</th>\n",
       "      <th>ret_mean_10</th>\n",
       "      <th>labels</th>\n",
       "      <th>train_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-01-02 08:00:00</td>\n",
       "      <td>109.308</td>\n",
       "      <td>109.323</td>\n",
       "      <td>108.902</td>\n",
       "      <td>108.950</td>\n",
       "      <td>20474.2598</td>\n",
       "      <td>2019-01-02 08:00:00</td>\n",
       "      <td>9.926973</td>\n",
       "      <td>0.972262</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.358</td>\n",
       "      <td>-0.003275</td>\n",
       "      <td>-0.003281</td>\n",
       "      <td>-2.853028</td>\n",
       "      <td>-0.000861</td>\n",
       "      <td>-0.000665</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-01-02 09:00:00</td>\n",
       "      <td>108.949</td>\n",
       "      <td>108.977</td>\n",
       "      <td>108.707</td>\n",
       "      <td>108.941</td>\n",
       "      <td>16183.7695</td>\n",
       "      <td>2019-01-02 09:00:00</td>\n",
       "      <td>9.691826</td>\n",
       "      <td>0.732430</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.078014</td>\n",
       "      <td>-0.000817</td>\n",
       "      <td>-0.000667</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-01-02 10:00:00</td>\n",
       "      <td>108.942</td>\n",
       "      <td>109.102</td>\n",
       "      <td>108.879</td>\n",
       "      <td>109.045</td>\n",
       "      <td>13739.5801</td>\n",
       "      <td>2019-01-02 10:00:00</td>\n",
       "      <td>9.528109</td>\n",
       "      <td>0.565451</td>\n",
       "      <td>1</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.821677</td>\n",
       "      <td>-0.000473</td>\n",
       "      <td>-0.000530</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-01-02 11:00:00</td>\n",
       "      <td>109.045</td>\n",
       "      <td>109.176</td>\n",
       "      <td>109.043</td>\n",
       "      <td>109.107</td>\n",
       "      <td>12859.2305</td>\n",
       "      <td>2019-01-02 11:00:00</td>\n",
       "      <td>9.461895</td>\n",
       "      <td>0.497918</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.486914</td>\n",
       "      <td>-0.000273</td>\n",
       "      <td>-0.000448</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-01-02 12:00:00</td>\n",
       "      <td>109.104</td>\n",
       "      <td>109.285</td>\n",
       "      <td>109.101</td>\n",
       "      <td>109.142</td>\n",
       "      <td>12204.0098</td>\n",
       "      <td>2019-01-02 12:00:00</td>\n",
       "      <td>9.409602</td>\n",
       "      <td>0.444583</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.271991</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>-0.000247</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37425</th>\n",
       "      <td>2024-12-31 17:00:00</td>\n",
       "      <td>157.370</td>\n",
       "      <td>157.546</td>\n",
       "      <td>157.310</td>\n",
       "      <td>157.365</td>\n",
       "      <td>31525.6895</td>\n",
       "      <td>2024-12-31 17:00:00</td>\n",
       "      <td>10.358590</td>\n",
       "      <td>1.412479</td>\n",
       "      <td>319</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.022871</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37426</th>\n",
       "      <td>2024-12-31 18:00:00</td>\n",
       "      <td>157.368</td>\n",
       "      <td>157.393</td>\n",
       "      <td>157.234</td>\n",
       "      <td>157.295</td>\n",
       "      <td>24407.4902</td>\n",
       "      <td>2024-12-31 18:00:00</td>\n",
       "      <td>10.102686</td>\n",
       "      <td>1.151477</td>\n",
       "      <td>319</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.000445</td>\n",
       "      <td>-0.000445</td>\n",
       "      <td>-0.392415</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37427</th>\n",
       "      <td>2024-12-31 19:00:00</td>\n",
       "      <td>157.297</td>\n",
       "      <td>157.311</td>\n",
       "      <td>157.236</td>\n",
       "      <td>157.308</td>\n",
       "      <td>18772.5898</td>\n",
       "      <td>2024-12-31 19:00:00</td>\n",
       "      <td>9.840206</td>\n",
       "      <td>0.883767</td>\n",
       "      <td>319</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.065386</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37428</th>\n",
       "      <td>2024-12-31 20:00:00</td>\n",
       "      <td>157.308</td>\n",
       "      <td>157.376</td>\n",
       "      <td>157.293</td>\n",
       "      <td>157.344</td>\n",
       "      <td>29975.6406</td>\n",
       "      <td>2024-12-31 20:00:00</td>\n",
       "      <td>10.308174</td>\n",
       "      <td>1.361058</td>\n",
       "      <td>319</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.192235</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37429</th>\n",
       "      <td>2024-12-31 21:00:00</td>\n",
       "      <td>157.344</td>\n",
       "      <td>157.347</td>\n",
       "      <td>157.178</td>\n",
       "      <td>157.184</td>\n",
       "      <td>5207.0698</td>\n",
       "      <td>2024-12-31 21:00:00</td>\n",
       "      <td>8.557965</td>\n",
       "      <td>-0.424022</td>\n",
       "      <td>319</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>-0.001017</td>\n",
       "      <td>-0.001017</td>\n",
       "      <td>-0.889183</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34242 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp     open     high      low    close      volume  \\\n",
       "10    2019-01-02 08:00:00  109.308  109.323  108.902  108.950  20474.2598   \n",
       "11    2019-01-02 09:00:00  108.949  108.977  108.707  108.941  16183.7695   \n",
       "12    2019-01-02 10:00:00  108.942  109.102  108.879  109.045  13739.5801   \n",
       "13    2019-01-02 11:00:00  109.045  109.176  109.043  109.107  12859.2305   \n",
       "14    2019-01-02 12:00:00  109.104  109.285  109.101  109.142  12204.0098   \n",
       "...                   ...      ...      ...      ...      ...         ...   \n",
       "37425 2024-12-31 17:00:00  157.370  157.546  157.310  157.365  31525.6895   \n",
       "37426 2024-12-31 18:00:00  157.368  157.393  157.234  157.295  24407.4902   \n",
       "37427 2024-12-31 19:00:00  157.297  157.311  157.236  157.308  18772.5898   \n",
       "37428 2024-12-31 20:00:00  157.308  157.376  157.293  157.344  29975.6406   \n",
       "37429 2024-12-31 21:00:00  157.344  157.347  157.178  157.184   5207.0698   \n",
       "\n",
       "                      time  log_volume  log_volume_scaled  time_group  \\\n",
       "10     2019-01-02 08:00:00    9.926973           0.972262           1   \n",
       "11     2019-01-02 09:00:00    9.691826           0.732430           1   \n",
       "12     2019-01-02 10:00:00    9.528109           0.565451           1   \n",
       "13     2019-01-02 11:00:00    9.461895           0.497918           1   \n",
       "14     2019-01-02 12:00:00    9.409602           0.444583           1   \n",
       "...                    ...         ...                ...         ...   \n",
       "37425  2024-12-31 17:00:00   10.358590           1.412479         319   \n",
       "37426  2024-12-31 18:00:00   10.102686           1.151477         319   \n",
       "37427  2024-12-31 19:00:00    9.840206           0.883767         319   \n",
       "37428  2024-12-31 20:00:00   10.308174           1.361058         319   \n",
       "37429  2024-12-31 21:00:00    8.557965          -0.424022         319   \n",
       "\n",
       "       close_delta  close_return  close_log_return  close_log_return_scaled  \\\n",
       "10          -0.358     -0.003275         -0.003281                -2.853028   \n",
       "11          -0.009     -0.000083         -0.000083                -0.078014   \n",
       "12           0.104      0.000955          0.000954                 0.821677   \n",
       "13           0.062      0.000569          0.000568                 0.486914   \n",
       "14           0.035      0.000321          0.000321                 0.271991   \n",
       "...            ...           ...               ...                      ...   \n",
       "37425       -0.003     -0.000019         -0.000019                -0.022871   \n",
       "37426       -0.070     -0.000445         -0.000445                -0.392415   \n",
       "37427        0.013      0.000083          0.000083                 0.065386   \n",
       "37428        0.036      0.000229          0.000229                 0.192235   \n",
       "37429       -0.160     -0.001017         -0.001017                -0.889183   \n",
       "\n",
       "       ret_mean_5  ret_mean_10  labels  train_label  \n",
       "10      -0.000861    -0.000665      -1            0  \n",
       "11      -0.000817    -0.000667      -1            0  \n",
       "12      -0.000473    -0.000530      -1            0  \n",
       "13      -0.000273    -0.000448      -1            0  \n",
       "14      -0.000304    -0.000247      -1            0  \n",
       "...           ...          ...     ...          ...  \n",
       "37425    0.000605     0.000742      -1            0  \n",
       "37426    0.000363     0.000731      -1            0  \n",
       "37427    0.000684     0.000425      -1            0  \n",
       "37428    0.000235     0.000324      -1            0  \n",
       "37429   -0.000234     0.000246      -1            0  \n",
       "\n",
       "[34242 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(PKL_PATH)\n",
    "\n",
    "df=df[df['timestamp'].dt.year <= 2024]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1afda6-b0fa-490c-a303-10fbf2b12162",
   "metadata": {},
   "source": [
    "## Create Datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3a5af5d-47df-4a22-8f5f-36233abe2010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_sequence_start_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1f6e4b8-512a-4b41-9b01-2e87405f58ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get valid indices that wont create sequences crossing time gaps\n",
    "IDs = get_sequence_start_indices(\n",
    "    df,\n",
    "    sequence_length=SEQUENCE_LENGTH,\n",
    "    horizon=HORIZON,\n",
    "    stride=STRIDE,\n",
    "    group_col='time_group',\n",
    ")\n",
    "# Initialize Data Module\n",
    "dm = ForexDataModule(\n",
    "    data=df,\n",
    "    IDs=IDs,\n",
    "    sequence_length=SEQUENCE_LENGTH,\n",
    "    target=TARGET_COLS,\n",
    "    features=FEATURES_COLS,\n",
    "    horizon=HORIZON,\n",
    "    batch_size=64,\n",
    "    val_split=0.2,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6814c3e7-8895-4797-a4bb-ba690afe1850",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRUModule(\n",
    "    n_features=len(FEATURES_COLS),\n",
    "    output_size=3,\n",
    "    n_hidden=256,\n",
    "    n_layers=3,\n",
    "    dropout=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649ae8aa-7cdd-4de0-879e-bb0ff2c83463",
   "metadata": {},
   "source": [
    "# Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02ad62b8-148d-44f4-b85c-28371fe6fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.profilers import SimpleProfiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f564291-d188-4a82-9ee7-f410cf7ebbc9",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19a7ebf8-027b-49d9-b832-1faeb7e8554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"prob_gru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0532979-2b4d-4e4b-b749-64b8d970f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler = SimpleProfiler(filename='profiler')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c875bac5-bf76-47f1-9747-db83ee2e8c85",
   "metadata": {},
   "source": [
    "### Earlystopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53b0a7f4-2390-4a73-87b2-b5fba3544d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=5,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396d16e5-6736-436f-bce5-208ff3312c8e",
   "metadata": {},
   "source": [
    "### Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "975aad1e-8076-4729-9408-57a099ff8616",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filename='best_checkpoint',\n",
    "    save_top_k=1,\n",
    "    save_last=True,\n",
    "    verbose=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7699cd-305d-4561-bd2d-d24e937448ef",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c97795a9-791e-4255-9a19-8ddeba6ea771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    # accelerator=\"gpu\",\n",
    "    # precision='16-mixed',\n",
    "    profiler=profiler,\n",
    "    callbacks=[checkpoint_callback, early_stopping],\n",
    "    max_epochs=200,\n",
    "    logger=logger,\n",
    "    gradient_clip_val=1.0\n",
    "    # num_sanity_val_steps=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "512481df-990b-4c2e-905b-4c8cab59a7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model         | GRUModel           | 989 K  | train\n",
      "1 | criterion     | CrossEntropyLoss   | 0      | train\n",
      "2 | test_accuracy | MulticlassAccuracy | 0      | train\n",
      "-------------------------------------------------------------\n",
      "989 K     Trainable params\n",
      "0         Non-trainable params\n",
      "989 K     Total params\n",
      "3.957     Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                timestamp     open     high      low    close      volume  \\\n",
      "30520 2023-11-21 19:00:00  148.343  148.594  148.238  148.315  20056.0996   \n",
      "30521 2023-11-21 20:00:00  148.314  148.429  148.273  148.388   8018.2700   \n",
      "30522 2023-11-21 21:00:00  148.386  148.416  148.335  148.380   3078.6599   \n",
      "30523 2023-11-21 22:00:00  148.364  148.396  148.233  148.237   1425.9700   \n",
      "30524 2023-11-21 23:00:00  148.237  148.275  148.017  148.147   6125.9800   \n",
      "30525 2023-11-22 00:00:00  148.146  148.299  148.079  148.233  14284.9502   \n",
      "30526 2023-11-22 01:00:00  148.238  148.355  148.029  148.298  22533.3691   \n",
      "30527 2023-11-22 02:00:00  148.298  148.332  148.133  148.236  11424.4199   \n",
      "30528 2023-11-22 03:00:00  148.235  148.280  148.095  148.212  10594.2002   \n",
      "30529 2023-11-22 04:00:00  148.214  148.389  148.202  148.376  11211.9297   \n",
      "30530 2023-11-22 05:00:00  148.376  148.803  148.368  148.752  16636.9902   \n",
      "30531 2023-11-22 06:00:00  148.753  149.053  148.735  148.932  16393.5605   \n",
      "30532 2023-11-22 07:00:00  148.931  148.974  148.814  148.960  20641.5508   \n",
      "30533 2023-11-22 08:00:00  148.960  149.350  148.846  149.318  24283.8906   \n",
      "30534 2023-11-22 09:00:00  149.318  149.323  148.951  149.105  22552.2598   \n",
      "30535 2023-11-22 10:00:00  149.104  149.155  148.893  148.900  20768.1602   \n",
      "30536 2023-11-22 11:00:00  148.900  148.914  148.703  148.768  21134.8398   \n",
      "30537 2023-11-22 12:00:00  148.766  148.842  148.589  148.735  25992.3008   \n",
      "30538 2023-11-22 13:00:00  148.736  149.237  148.605  149.233  44370.0195   \n",
      "30539 2023-11-22 14:00:00  149.234  149.468  149.197  149.352  44431.3516   \n",
      "30540 2023-11-22 15:00:00  149.352  149.747  149.341  149.681  46589.6406   \n",
      "30541 2023-11-22 16:00:00  149.681  149.745  149.545  149.677  25404.3398   \n",
      "30542 2023-11-22 17:00:00  149.678  149.705  149.547  149.614  13135.8203   \n",
      "30543 2023-11-22 18:00:00  149.616  149.699  149.578  149.671   9880.5596   \n",
      "30544 2023-11-22 19:00:00  149.670  149.670  149.567  149.578  10810.6504   \n",
      "30545 2023-11-22 20:00:00  149.578  149.621  149.565  149.598   5097.1001   \n",
      "30546 2023-11-22 21:00:00  149.599  149.616  149.512  149.533   3478.8000   \n",
      "30547 2023-11-22 22:00:00  149.524  149.542  149.488  149.510   2246.7400   \n",
      "30548 2023-11-22 23:00:00  149.513  149.532  149.458  149.461   3650.5400   \n",
      "30549 2023-11-23 00:00:00  149.460  149.460  149.230  149.259  12436.2998   \n",
      "\n",
      "                      time  log_volume  log_volume_scaled  time_group  \\\n",
      "30520  2023-11-21 19:00:00    9.906338           0.951217         259   \n",
      "30521  2023-11-21 20:00:00    8.989603           0.016216         259   \n",
      "30522  2023-11-21 21:00:00    8.032574          -0.959880         259   \n",
      "30523  2023-11-21 22:00:00    7.263309          -1.744472         259   \n",
      "30524  2023-11-21 23:00:00    8.720457          -0.258292         259   \n",
      "30525  2023-11-22 00:00:00    9.567032           0.605150         259   \n",
      "30526  2023-11-22 01:00:00   10.022797           1.069995         259   \n",
      "30527  2023-11-22 02:00:00    9.343596           0.377262         259   \n",
      "30528  2023-11-22 03:00:00    9.268156           0.300320         259   \n",
      "30529  2023-11-22 04:00:00    9.324823           0.358115         259   \n",
      "30530  2023-11-22 05:00:00    9.719444           0.760599         259   \n",
      "30531  2023-11-22 06:00:00    9.704705           0.745566         259   \n",
      "30532  2023-11-22 07:00:00    9.935110           0.980561         259   \n",
      "30533  2023-11-22 08:00:00   10.097610           1.146299         259   \n",
      "30534  2023-11-22 09:00:00   10.023635           1.070850         259   \n",
      "30535  2023-11-22 10:00:00    9.941224           0.986798         259   \n",
      "30536  2023-11-22 11:00:00    9.958725           1.004647         259   \n",
      "30537  2023-11-22 12:00:00   10.165594           1.215638         259   \n",
      "30538  2023-11-22 13:00:00   10.700342           1.761040         259   \n",
      "30539  2023-11-22 14:00:00   10.701723           1.762448         259   \n",
      "30540  2023-11-22 15:00:00   10.749155           1.810825         259   \n",
      "30541  2023-11-22 16:00:00   10.142715           1.192302         259   \n",
      "30542  2023-11-22 17:00:00    9.483174           0.519622         259   \n",
      "30543  2023-11-22 18:00:00    9.198426           0.229200         259   \n",
      "30544  2023-11-22 19:00:00    9.288380           0.320946         259   \n",
      "30545  2023-11-22 20:00:00    8.536623          -0.445788         259   \n",
      "30546  2023-11-22 21:00:00    8.154730          -0.835290         259   \n",
      "30547  2023-11-22 22:00:00    7.717681          -1.281047         259   \n",
      "30548  2023-11-22 23:00:00    8.202904          -0.786156         259   \n",
      "30549  2023-11-23 00:00:00    9.428455           0.463812         259   \n",
      "\n",
      "       close_delta  close_return  close_log_return  close_log_return_scaled  \\\n",
      "30520       -0.035     -0.000236         -0.000236                -0.211081   \n",
      "30521        0.073      0.000492          0.000492                 0.420673   \n",
      "30522       -0.008     -0.000054         -0.000054                -0.053113   \n",
      "30523       -0.143     -0.000964         -0.000964                -0.843026   \n",
      "30524       -0.090     -0.000607         -0.000607                -0.533335   \n",
      "30525        0.086      0.000581          0.000580                 0.497262   \n",
      "30526        0.065      0.000438          0.000438                 0.374099   \n",
      "30527       -0.062     -0.000418         -0.000418                -0.369194   \n",
      "30528       -0.024     -0.000162         -0.000162                -0.146833   \n",
      "30529        0.164      0.001107          0.001106                 0.953334   \n",
      "30530        0.376      0.002534          0.002531                 2.189876   \n",
      "30531        0.180      0.001210          0.001209                 1.043082   \n",
      "30532        0.028      0.000188          0.000188                 0.156799   \n",
      "30533        0.358      0.002403          0.002400                 2.076677   \n",
      "30534       -0.213     -0.001426         -0.001428                -1.245056   \n",
      "30535       -0.205     -0.001375         -0.001376                -1.200203   \n",
      "30536       -0.132     -0.000887         -0.000887                -0.775938   \n",
      "30537       -0.033     -0.000222         -0.000222                -0.198837   \n",
      "30538        0.498      0.003348          0.003343                 2.894276   \n",
      "30539        0.119      0.000797          0.000797                 0.685355   \n",
      "30540        0.329      0.002203          0.002200                 1.903108   \n",
      "30541       -0.004     -0.000027         -0.000027                -0.029518   \n",
      "30542       -0.063     -0.000421         -0.000421                -0.371650   \n",
      "30543        0.057      0.000381          0.000381                 0.324207   \n",
      "30544       -0.093     -0.000621         -0.000622                -0.545688   \n",
      "30545        0.020      0.000134          0.000134                 0.109691   \n",
      "30546       -0.065     -0.000434         -0.000435                -0.383449   \n",
      "30547       -0.023     -0.000154         -0.000154                -0.139810   \n",
      "30548       -0.049     -0.000328         -0.000328                -0.290772   \n",
      "30549       -0.202     -0.001352         -0.001352                -1.179916   \n",
      "\n",
      "       ret_mean_5  ret_mean_10  labels  train_label  \n",
      "30520    0.001059     0.000366       1            2  \n",
      "30521    0.000806     0.000546       1            2  \n",
      "30522    0.000674     0.000448       1            2  \n",
      "30523    0.000375     0.000444       1            2  \n",
      "30524   -0.000274     0.000356       1            2  \n",
      "30525   -0.000111     0.000474       1            2  \n",
      "30526   -0.000121     0.000342       1            2  \n",
      "30527   -0.000194     0.000240       1            2  \n",
      "30528   -0.000034     0.000171       1            2  \n",
      "30529    0.000309     0.000018       1            2  \n",
      "30530    0.000699     0.000294       1            2  \n",
      "30531    0.000853     0.000366       1            2  \n",
      "30532    0.000974     0.000390       0            1  \n",
      "30533    0.001487     0.000727      -1            0  \n",
      "30534    0.000980     0.000645       0            1  \n",
      "30535    0.000199     0.000449       1            2  \n",
      "30536   -0.000220     0.000316       1            2  \n",
      "30537   -0.000302     0.000336       1            2  \n",
      "30538   -0.000114     0.000687       0            1  \n",
      "30539    0.000331     0.000656       0            1  \n",
      "30540    0.001046     0.000623      -1            0  \n",
      "30541    0.001218     0.000499      -1            0  \n",
      "30542    0.001178     0.000438      -1            0  \n",
      "30543    0.000586     0.000236      -1            0  \n",
      "30544    0.000302     0.000317      -1            0  \n",
      "30545   -0.000111     0.000468      -1            0  \n",
      "30546   -0.000193     0.000513      -1            0  \n",
      "30547   -0.000139     0.000520       0            1  \n",
      "30548   -0.000281     0.000153       0            1  \n",
      "30549   -0.000427    -0.000062       0            1  \n",
      "timestamp                  2023-11-23 01:00:00\n",
      "open                                   149.258\n",
      "high                                    149.32\n",
      "low                                    149.162\n",
      "close                                  149.177\n",
      "volume                              17131.3496\n",
      "time                       2023-11-23 01:00:00\n",
      "log_volume                            9.748724\n",
      "log_volume_scaled                     0.790462\n",
      "time_group                                 259\n",
      "close_delta                             -0.082\n",
      "close_return                         -0.000549\n",
      "close_log_return                      -0.00055\n",
      "close_log_return_scaled              -0.483189\n",
      "ret_mean_5                           -0.000564\n",
      "ret_mean_10                          -0.000337\n",
      "labels                                       0\n",
      "train_label                                  1\n",
      "Name: 30550, dtype: object\n",
      "                timestamp     open     high      low    close      volume  \\\n",
      "19110 2022-01-25 09:00:00  113.898  114.107  113.897  114.053  10622.0596   \n",
      "19111 2022-01-25 10:00:00  114.053  114.150  114.038  114.107   6693.4902   \n",
      "19112 2022-01-25 11:00:00  114.106  114.155  113.975  114.005   8371.4902   \n",
      "19113 2022-01-25 12:00:00  114.008  114.066  113.943  114.049   6772.3901   \n",
      "19114 2022-01-25 13:00:00  114.047  114.060  113.870  113.898  10480.6299   \n",
      "19115 2022-01-25 14:00:00  113.897  113.946  113.813  113.876  13720.3604   \n",
      "19116 2022-01-25 15:00:00  113.878  113.992  113.778  113.949  17926.8203   \n",
      "19117 2022-01-25 16:00:00  113.949  113.957  113.858  113.870   7610.3701   \n",
      "19118 2022-01-25 17:00:00  113.870  113.908  113.826  113.841   3626.1399   \n",
      "19119 2022-01-25 18:00:00  113.842  113.924  113.802  113.870   3677.5100   \n",
      "19120 2022-01-25 19:00:00  113.870  113.938  113.851  113.920   2482.2500   \n",
      "19121 2022-01-25 20:00:00  113.921  113.943  113.884  113.900   3515.6899   \n",
      "19122 2022-01-25 21:00:00  113.900  113.902  113.840  113.853   1387.6700   \n",
      "19123 2022-01-25 22:00:00  113.852  113.883  113.840  113.852   7597.6699   \n",
      "19124 2022-01-25 23:00:00  113.850  113.925  113.845  113.892   2829.9099   \n",
      "19125 2022-01-26 00:00:00  113.895  113.898  113.784  113.824   6671.2100   \n",
      "19126 2022-01-26 01:00:00  113.824  113.872  113.776  113.866   3990.7600   \n",
      "19127 2022-01-26 02:00:00  113.866  113.894  113.829  113.860   2336.4399   \n",
      "19128 2022-01-26 03:00:00  113.860  113.888  113.854  113.865   2207.1799   \n",
      "19129 2022-01-26 04:00:00  113.867  113.929  113.859  113.920   2006.3600   \n",
      "19130 2022-01-26 05:00:00  113.920  113.920  113.874  113.894   2331.4099   \n",
      "19131 2022-01-26 06:00:00  113.894  113.969  113.870  113.966   2459.2500   \n",
      "19132 2022-01-26 07:00:00  113.967  113.986  113.923  113.984   4136.4102   \n",
      "19133 2022-01-26 08:00:00  113.984  114.152  113.973  114.143   7057.9302   \n",
      "19134 2022-01-26 09:00:00  114.144  114.180  114.073  114.124   5437.1299   \n",
      "19135 2022-01-26 10:00:00  114.125  114.235  114.099  114.162   4252.7598   \n",
      "19136 2022-01-26 11:00:00  114.163  114.197  114.129  114.196   4907.1899   \n",
      "19137 2022-01-26 12:00:00  114.197  114.209  114.154  114.185   4477.0601   \n",
      "19138 2022-01-26 13:00:00  114.183  114.314  114.180  114.304   5867.2100   \n",
      "19139 2022-01-26 14:00:00  114.304  114.362  114.225  114.351   9455.4600   \n",
      "\n",
      "                      time  log_volume  log_volume_scaled  time_group  \\\n",
      "19110  2022-01-25 09:00:00    9.270782           0.302998         164   \n",
      "19111  2022-01-25 10:00:00    8.809040          -0.167944         164   \n",
      "19112  2022-01-25 11:00:00    9.032707           0.060179         164   \n",
      "19113  2022-01-25 12:00:00    8.820757          -0.155994         164   \n",
      "19114  2022-01-25 13:00:00    9.257379           0.289328         164   \n",
      "19115  2022-01-25 14:00:00    9.526709           0.564024         164   \n",
      "19116  2022-01-25 15:00:00    9.794109           0.836751         164   \n",
      "19117  2022-01-25 16:00:00    8.937398          -0.037028         164   \n",
      "19118  2022-01-25 17:00:00    8.196200          -0.792994         164   \n",
      "19119  2022-01-25 18:00:00    8.210263          -0.778651         164   \n",
      "19120  2022-01-25 19:00:00    7.817323          -1.179419         164   \n",
      "19121  2022-01-25 20:00:00    8.165275          -0.824535         164   \n",
      "19122  2022-01-25 21:00:00    7.236102          -1.772221         164   \n",
      "19123  2022-01-25 22:00:00    8.935728          -0.038731         164   \n",
      "19124  2022-01-25 23:00:00    7.948353          -1.045779         164   \n",
      "19125  2022-01-26 00:00:00    8.805706          -0.171344         164   \n",
      "19126  2022-01-26 01:00:00    8.291988          -0.695298         164   \n",
      "19127  2022-01-26 02:00:00    7.756812          -1.241137         164   \n",
      "19128  2022-01-26 03:00:00    7.699924          -1.299158         164   \n",
      "19129  2022-01-26 04:00:00    7.604576          -1.396406         164   \n",
      "19130  2022-01-26 05:00:00    7.754657          -1.243334         164   \n",
      "19131  2022-01-26 06:00:00    7.808018          -1.188910         164   \n",
      "19132  2022-01-26 07:00:00    8.327825          -0.658746         164   \n",
      "19133  2022-01-26 08:00:00    8.862049          -0.113879         164   \n",
      "19134  2022-01-26 09:00:00    8.601191          -0.379935         164   \n",
      "19135  2022-01-26 10:00:00    8.355559          -0.630460         164   \n",
      "19136  2022-01-26 11:00:00    8.498660          -0.484507         164   \n",
      "19137  2022-01-26 12:00:00    8.406945          -0.578050         164   \n",
      "19138  2022-01-26 13:00:00    8.677305          -0.302304         164   \n",
      "19139  2022-01-26 14:00:00    9.154453           0.184351         164   \n",
      "\n",
      "       close_delta  close_return  close_log_return  close_log_return_scaled  \\\n",
      "19110        0.155      0.001361          0.001360                 1.173771   \n",
      "19111        0.054      0.000473          0.000473                 0.404426   \n",
      "19112       -0.102     -0.000894         -0.000894                -0.782362   \n",
      "19113        0.044      0.000386          0.000386                 0.328516   \n",
      "19114       -0.151     -0.001324         -0.001325                -1.155994   \n",
      "19115       -0.022     -0.000193         -0.000193                -0.173957   \n",
      "19116        0.073      0.000641          0.000641                 0.549768   \n",
      "19117       -0.079     -0.000693         -0.000694                -0.608147   \n",
      "19118       -0.029     -0.000255         -0.000255                -0.227354   \n",
      "19119        0.029      0.000255          0.000255                 0.214697   \n",
      "19120        0.050      0.000439          0.000439                 0.374618   \n",
      "19121       -0.020     -0.000176         -0.000176                -0.158687   \n",
      "19122       -0.047     -0.000413         -0.000413                -0.364476   \n",
      "19123       -0.001     -0.000009         -0.000009                -0.013950   \n",
      "19124        0.040      0.000351          0.000351                 0.298490   \n",
      "19125       -0.068     -0.000597         -0.000597                -0.524584   \n",
      "19126        0.042      0.000369          0.000369                 0.313807   \n",
      "19127       -0.006     -0.000053         -0.000053                -0.052055   \n",
      "19128        0.005      0.000044          0.000044                 0.031777   \n",
      "19129        0.055      0.000483          0.000483                 0.412722   \n",
      "19130       -0.026     -0.000228         -0.000228                -0.204400   \n",
      "19131        0.072      0.000632          0.000632                 0.542066   \n",
      "19132        0.018      0.000158          0.000158                 0.130716   \n",
      "19133        0.159      0.001395          0.001394                 1.203291   \n",
      "19134       -0.019     -0.000166         -0.000166                -0.150786   \n",
      "19135        0.038      0.000333          0.000333                 0.282562   \n",
      "19136        0.034      0.000298          0.000298                 0.252071   \n",
      "19137       -0.011     -0.000096         -0.000096                -0.089920   \n",
      "19138        0.119      0.001042          0.001042                 0.897550   \n",
      "19139        0.047      0.000411          0.000411                 0.350406   \n",
      "\n",
      "         ret_mean_5  ret_mean_10  labels  train_label  \n",
      "19110  5.812758e-04     0.000035       1            2  \n",
      "19111  5.388166e-04     0.000097       1            2  \n",
      "19112  2.457542e-04     0.000143       1            2  \n",
      "19113  2.842904e-04     0.000213       1            2  \n",
      "19114  3.122502e-18     0.000108       1            2  \n",
      "19115 -3.106231e-04     0.000135       1            2  \n",
      "19116 -2.771250e-04     0.000131       1            2  \n",
      "19117 -2.369721e-04     0.000004       1            2  \n",
      "19118 -3.650885e-04    -0.000040       1            2  \n",
      "19119 -4.917284e-05    -0.000025       1            2  \n",
      "19120  7.726211e-05    -0.000117       1            2  \n",
      "19121 -8.602188e-05    -0.000182       1            2  \n",
      "19122 -2.986084e-05    -0.000133       1            2  \n",
      "19123  1.932427e-05    -0.000173       1            2  \n",
      "19124  3.863682e-05    -0.000005       1            2  \n",
      "19125 -1.686104e-04    -0.000046       1            2  \n",
      "19126 -5.971040e-05    -0.000073       1            2  \n",
      "19127  1.229618e-05    -0.000009       1            2  \n",
      "19128  2.283536e-05     0.000021       1            2  \n",
      "19129  4.916335e-05     0.000044       1            2  \n",
      "19130  1.229591e-04    -0.000023       1            2  \n",
      "19131  1.755680e-04     0.000058       1            2  \n",
      "19132  2.176928e-04     0.000115       1            2  \n",
      "19133  4.877024e-04     0.000255       1            2  \n",
      "19134  3.578258e-04     0.000203       1            2  \n",
      "19135  4.700602e-04     0.000297       1            2  \n",
      "19136  4.032224e-04     0.000289       1            2  \n",
      "19137  3.523705e-04     0.000285       1            2  \n",
      "19138  2.819035e-04     0.000385       1            2  \n",
      "19139  3.974178e-04     0.000378       1            2  \n",
      "timestamp                  2022-01-26 15:00:00\n",
      "open                                   114.351\n",
      "high                                   114.383\n",
      "low                                    114.217\n",
      "close                                   114.32\n",
      "volume                               9571.8203\n",
      "time                       2022-01-26 15:00:00\n",
      "log_volume                            9.166683\n",
      "log_volume_scaled                     0.196825\n",
      "time_group                                 164\n",
      "close_delta                             -0.031\n",
      "close_return                         -0.000271\n",
      "close_log_return                     -0.000271\n",
      "close_log_return_scaled              -0.241605\n",
      "ret_mean_5                            0.000277\n",
      "ret_mean_10                           0.000373\n",
      "labels                                       1\n",
      "train_label                                  2\n",
      "Name: 19140, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9b852c8ded4b908754250556d6f24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoyo\\miniconda3\\envs\\fxml\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\yoyo\\miniconda3\\envs\\fxml\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa34e26d3eb44beb01a1ecd6d9b9064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d8829fa623437783117825d756f32a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.095\n",
      "Epoch 0, global step 62: 'val_loss' reached 1.09510 (best 1.09510), saving model to 'lightning_logs\\\\prob_gru\\\\version_6\\\\checkpoints\\\\best_checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1340d4a40224c38aa51687924ccef29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 1.093\n",
      "Epoch 1, global step 124: 'val_loss' reached 1.09325 (best 1.09325), saving model to 'lightning_logs\\\\prob_gru\\\\version_6\\\\checkpoints\\\\best_checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2dfa79f46546e883fe6e175b89917d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 186: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6092dc821af74cd389d2262bf40dc9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.012 >= min_delta = 0.0. New best score: 1.081\n",
      "Epoch 3, global step 248: 'val_loss' reached 1.08121 (best 1.08121), saving model to 'lightning_logs\\\\prob_gru\\\\version_6\\\\checkpoints\\\\best_checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b46d42eef7a4c4397b8ef2bf8197bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.050 >= min_delta = 0.0. New best score: 1.032\n",
      "Epoch 4, global step 310: 'val_loss' reached 1.03154 (best 1.03154), saving model to 'lightning_logs\\\\prob_gru\\\\version_6\\\\checkpoints\\\\best_checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82e6e7e442c4a70b8fceec79ce7a42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 372: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572317c0d12f4e2eb57b56fac0954a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 1.030\n",
      "Epoch 6, global step 434: 'val_loss' reached 1.02986 (best 1.02986), saving model to 'lightning_logs\\\\prob_gru\\\\version_6\\\\checkpoints\\\\best_checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f01de6c7cd4e199810defc5b4b4bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 496: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab889c0c3d14405b1d3b6ae7b4ece09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 1.027\n",
      "Epoch 8, global step 558: 'val_loss' reached 1.02661 (best 1.02661), saving model to 'lightning_logs\\\\prob_gru\\\\version_6\\\\checkpoints\\\\best_checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfcf4dea94af4a47ba39f76316ecf191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 1.025\n",
      "Epoch 9, global step 620: 'val_loss' reached 1.02471 (best 1.02471), saving model to 'lightning_logs\\\\prob_gru\\\\version_6\\\\checkpoints\\\\best_checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898539507d1d4660b78751f512828f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 682: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd7593313e24c3ab1ed74d7edf7dd43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 744: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735fbe29197a45f79ff6846223e6f058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 1.024\n",
      "Epoch 12, global step 806: 'val_loss' reached 1.02409 (best 1.02409), saving model to 'lightning_logs\\\\prob_gru\\\\version_6\\\\checkpoints\\\\best_checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8e242befbf445ba750bd5ab763c3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 1.023\n",
      "Epoch 13, global step 868: 'val_loss' reached 1.02267 (best 1.02267), saving model to 'lightning_logs\\\\prob_gru\\\\version_6\\\\checkpoints\\\\best_checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031fedaf1a434c2cae98687e3353a130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 930: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f04667a559643b5af24086afbbe6008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 992: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24752db3b03d495da9a2e1ad62671eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 1054: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0773286357bd43cc9896d3864ddcbe73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 1116: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c3a69f16c946cb87b58d6a8a09794d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 1.022\n",
      "Epoch 18, global step 1178: 'val_loss' reached 1.02161 (best 1.02161), saving model to 'lightning_logs\\\\prob_gru\\\\version_6\\\\checkpoints\\\\best_checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec7dfad4a1a432b97d3266fcc42d69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 1240: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3e1706f75946f5931612278c8740b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 1302: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a728dee97d10491ab74210bbb40fe5e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 1364: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd0b7371b92a4627bffa0b15e3d8e9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 1426: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7e590fc14b4c2d8ecd1285cc76ed06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 5 records. Best score: 1.022. Signaling Trainer to stop.\n",
      "Epoch 23, global step 1488: 'val_loss' was not in top 1\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "638751b6-d431-4396-8030-0c98aba2faed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                timestamp     open     high      low    close      volume  \\\n",
      "30520 2023-11-21 19:00:00  148.343  148.594  148.238  148.315  20056.0996   \n",
      "30521 2023-11-21 20:00:00  148.314  148.429  148.273  148.388   8018.2700   \n",
      "30522 2023-11-21 21:00:00  148.386  148.416  148.335  148.380   3078.6599   \n",
      "30523 2023-11-21 22:00:00  148.364  148.396  148.233  148.237   1425.9700   \n",
      "30524 2023-11-21 23:00:00  148.237  148.275  148.017  148.147   6125.9800   \n",
      "30525 2023-11-22 00:00:00  148.146  148.299  148.079  148.233  14284.9502   \n",
      "30526 2023-11-22 01:00:00  148.238  148.355  148.029  148.298  22533.3691   \n",
      "30527 2023-11-22 02:00:00  148.298  148.332  148.133  148.236  11424.4199   \n",
      "30528 2023-11-22 03:00:00  148.235  148.280  148.095  148.212  10594.2002   \n",
      "30529 2023-11-22 04:00:00  148.214  148.389  148.202  148.376  11211.9297   \n",
      "30530 2023-11-22 05:00:00  148.376  148.803  148.368  148.752  16636.9902   \n",
      "30531 2023-11-22 06:00:00  148.753  149.053  148.735  148.932  16393.5605   \n",
      "30532 2023-11-22 07:00:00  148.931  148.974  148.814  148.960  20641.5508   \n",
      "30533 2023-11-22 08:00:00  148.960  149.350  148.846  149.318  24283.8906   \n",
      "30534 2023-11-22 09:00:00  149.318  149.323  148.951  149.105  22552.2598   \n",
      "30535 2023-11-22 10:00:00  149.104  149.155  148.893  148.900  20768.1602   \n",
      "30536 2023-11-22 11:00:00  148.900  148.914  148.703  148.768  21134.8398   \n",
      "30537 2023-11-22 12:00:00  148.766  148.842  148.589  148.735  25992.3008   \n",
      "30538 2023-11-22 13:00:00  148.736  149.237  148.605  149.233  44370.0195   \n",
      "30539 2023-11-22 14:00:00  149.234  149.468  149.197  149.352  44431.3516   \n",
      "30540 2023-11-22 15:00:00  149.352  149.747  149.341  149.681  46589.6406   \n",
      "30541 2023-11-22 16:00:00  149.681  149.745  149.545  149.677  25404.3398   \n",
      "30542 2023-11-22 17:00:00  149.678  149.705  149.547  149.614  13135.8203   \n",
      "30543 2023-11-22 18:00:00  149.616  149.699  149.578  149.671   9880.5596   \n",
      "30544 2023-11-22 19:00:00  149.670  149.670  149.567  149.578  10810.6504   \n",
      "30545 2023-11-22 20:00:00  149.578  149.621  149.565  149.598   5097.1001   \n",
      "30546 2023-11-22 21:00:00  149.599  149.616  149.512  149.533   3478.8000   \n",
      "30547 2023-11-22 22:00:00  149.524  149.542  149.488  149.510   2246.7400   \n",
      "30548 2023-11-22 23:00:00  149.513  149.532  149.458  149.461   3650.5400   \n",
      "30549 2023-11-23 00:00:00  149.460  149.460  149.230  149.259  12436.2998   \n",
      "\n",
      "                      time  log_volume  log_volume_scaled  time_group  \\\n",
      "30520  2023-11-21 19:00:00    9.906338           0.951217         259   \n",
      "30521  2023-11-21 20:00:00    8.989603           0.016216         259   \n",
      "30522  2023-11-21 21:00:00    8.032574          -0.959880         259   \n",
      "30523  2023-11-21 22:00:00    7.263309          -1.744472         259   \n",
      "30524  2023-11-21 23:00:00    8.720457          -0.258292         259   \n",
      "30525  2023-11-22 00:00:00    9.567032           0.605150         259   \n",
      "30526  2023-11-22 01:00:00   10.022797           1.069995         259   \n",
      "30527  2023-11-22 02:00:00    9.343596           0.377262         259   \n",
      "30528  2023-11-22 03:00:00    9.268156           0.300320         259   \n",
      "30529  2023-11-22 04:00:00    9.324823           0.358115         259   \n",
      "30530  2023-11-22 05:00:00    9.719444           0.760599         259   \n",
      "30531  2023-11-22 06:00:00    9.704705           0.745566         259   \n",
      "30532  2023-11-22 07:00:00    9.935110           0.980561         259   \n",
      "30533  2023-11-22 08:00:00   10.097610           1.146299         259   \n",
      "30534  2023-11-22 09:00:00   10.023635           1.070850         259   \n",
      "30535  2023-11-22 10:00:00    9.941224           0.986798         259   \n",
      "30536  2023-11-22 11:00:00    9.958725           1.004647         259   \n",
      "30537  2023-11-22 12:00:00   10.165594           1.215638         259   \n",
      "30538  2023-11-22 13:00:00   10.700342           1.761040         259   \n",
      "30539  2023-11-22 14:00:00   10.701723           1.762448         259   \n",
      "30540  2023-11-22 15:00:00   10.749155           1.810825         259   \n",
      "30541  2023-11-22 16:00:00   10.142715           1.192302         259   \n",
      "30542  2023-11-22 17:00:00    9.483174           0.519622         259   \n",
      "30543  2023-11-22 18:00:00    9.198426           0.229200         259   \n",
      "30544  2023-11-22 19:00:00    9.288380           0.320946         259   \n",
      "30545  2023-11-22 20:00:00    8.536623          -0.445788         259   \n",
      "30546  2023-11-22 21:00:00    8.154730          -0.835290         259   \n",
      "30547  2023-11-22 22:00:00    7.717681          -1.281047         259   \n",
      "30548  2023-11-22 23:00:00    8.202904          -0.786156         259   \n",
      "30549  2023-11-23 00:00:00    9.428455           0.463812         259   \n",
      "\n",
      "       close_delta  close_return  close_log_return  close_log_return_scaled  \\\n",
      "30520       -0.035     -0.000236         -0.000236                -0.211081   \n",
      "30521        0.073      0.000492          0.000492                 0.420673   \n",
      "30522       -0.008     -0.000054         -0.000054                -0.053113   \n",
      "30523       -0.143     -0.000964         -0.000964                -0.843026   \n",
      "30524       -0.090     -0.000607         -0.000607                -0.533335   \n",
      "30525        0.086      0.000581          0.000580                 0.497262   \n",
      "30526        0.065      0.000438          0.000438                 0.374099   \n",
      "30527       -0.062     -0.000418         -0.000418                -0.369194   \n",
      "30528       -0.024     -0.000162         -0.000162                -0.146833   \n",
      "30529        0.164      0.001107          0.001106                 0.953334   \n",
      "30530        0.376      0.002534          0.002531                 2.189876   \n",
      "30531        0.180      0.001210          0.001209                 1.043082   \n",
      "30532        0.028      0.000188          0.000188                 0.156799   \n",
      "30533        0.358      0.002403          0.002400                 2.076677   \n",
      "30534       -0.213     -0.001426         -0.001428                -1.245056   \n",
      "30535       -0.205     -0.001375         -0.001376                -1.200203   \n",
      "30536       -0.132     -0.000887         -0.000887                -0.775938   \n",
      "30537       -0.033     -0.000222         -0.000222                -0.198837   \n",
      "30538        0.498      0.003348          0.003343                 2.894276   \n",
      "30539        0.119      0.000797          0.000797                 0.685355   \n",
      "30540        0.329      0.002203          0.002200                 1.903108   \n",
      "30541       -0.004     -0.000027         -0.000027                -0.029518   \n",
      "30542       -0.063     -0.000421         -0.000421                -0.371650   \n",
      "30543        0.057      0.000381          0.000381                 0.324207   \n",
      "30544       -0.093     -0.000621         -0.000622                -0.545688   \n",
      "30545        0.020      0.000134          0.000134                 0.109691   \n",
      "30546       -0.065     -0.000434         -0.000435                -0.383449   \n",
      "30547       -0.023     -0.000154         -0.000154                -0.139810   \n",
      "30548       -0.049     -0.000328         -0.000328                -0.290772   \n",
      "30549       -0.202     -0.001352         -0.001352                -1.179916   \n",
      "\n",
      "       ret_mean_5  ret_mean_10  labels  train_label  \n",
      "30520    0.001059     0.000366       1            2  \n",
      "30521    0.000806     0.000546       1            2  \n",
      "30522    0.000674     0.000448       1            2  \n",
      "30523    0.000375     0.000444       1            2  \n",
      "30524   -0.000274     0.000356       1            2  \n",
      "30525   -0.000111     0.000474       1            2  \n",
      "30526   -0.000121     0.000342       1            2  \n",
      "30527   -0.000194     0.000240       1            2  \n",
      "30528   -0.000034     0.000171       1            2  \n",
      "30529    0.000309     0.000018       1            2  \n",
      "30530    0.000699     0.000294       1            2  \n",
      "30531    0.000853     0.000366       1            2  \n",
      "30532    0.000974     0.000390       0            1  \n",
      "30533    0.001487     0.000727      -1            0  \n",
      "30534    0.000980     0.000645       0            1  \n",
      "30535    0.000199     0.000449       1            2  \n",
      "30536   -0.000220     0.000316       1            2  \n",
      "30537   -0.000302     0.000336       1            2  \n",
      "30538   -0.000114     0.000687       0            1  \n",
      "30539    0.000331     0.000656       0            1  \n",
      "30540    0.001046     0.000623      -1            0  \n",
      "30541    0.001218     0.000499      -1            0  \n",
      "30542    0.001178     0.000438      -1            0  \n",
      "30543    0.000586     0.000236      -1            0  \n",
      "30544    0.000302     0.000317      -1            0  \n",
      "30545   -0.000111     0.000468      -1            0  \n",
      "30546   -0.000193     0.000513      -1            0  \n",
      "30547   -0.000139     0.000520       0            1  \n",
      "30548   -0.000281     0.000153       0            1  \n",
      "30549   -0.000427    -0.000062       0            1  \n",
      "timestamp                  2023-11-23 01:00:00\n",
      "open                                   149.258\n",
      "high                                    149.32\n",
      "low                                    149.162\n",
      "close                                  149.177\n",
      "volume                              17131.3496\n",
      "time                       2023-11-23 01:00:00\n",
      "log_volume                            9.748724\n",
      "log_volume_scaled                     0.790462\n",
      "time_group                                 259\n",
      "close_delta                             -0.082\n",
      "close_return                         -0.000549\n",
      "close_log_return                      -0.00055\n",
      "close_log_return_scaled              -0.483189\n",
      "ret_mean_5                           -0.000564\n",
      "ret_mean_10                          -0.000337\n",
      "labels                                       0\n",
      "train_label                                  1\n",
      "Name: 30550, dtype: object\n",
      "                timestamp     open     high      low    close      volume  \\\n",
      "19110 2022-01-25 09:00:00  113.898  114.107  113.897  114.053  10622.0596   \n",
      "19111 2022-01-25 10:00:00  114.053  114.150  114.038  114.107   6693.4902   \n",
      "19112 2022-01-25 11:00:00  114.106  114.155  113.975  114.005   8371.4902   \n",
      "19113 2022-01-25 12:00:00  114.008  114.066  113.943  114.049   6772.3901   \n",
      "19114 2022-01-25 13:00:00  114.047  114.060  113.870  113.898  10480.6299   \n",
      "19115 2022-01-25 14:00:00  113.897  113.946  113.813  113.876  13720.3604   \n",
      "19116 2022-01-25 15:00:00  113.878  113.992  113.778  113.949  17926.8203   \n",
      "19117 2022-01-25 16:00:00  113.949  113.957  113.858  113.870   7610.3701   \n",
      "19118 2022-01-25 17:00:00  113.870  113.908  113.826  113.841   3626.1399   \n",
      "19119 2022-01-25 18:00:00  113.842  113.924  113.802  113.870   3677.5100   \n",
      "19120 2022-01-25 19:00:00  113.870  113.938  113.851  113.920   2482.2500   \n",
      "19121 2022-01-25 20:00:00  113.921  113.943  113.884  113.900   3515.6899   \n",
      "19122 2022-01-25 21:00:00  113.900  113.902  113.840  113.853   1387.6700   \n",
      "19123 2022-01-25 22:00:00  113.852  113.883  113.840  113.852   7597.6699   \n",
      "19124 2022-01-25 23:00:00  113.850  113.925  113.845  113.892   2829.9099   \n",
      "19125 2022-01-26 00:00:00  113.895  113.898  113.784  113.824   6671.2100   \n",
      "19126 2022-01-26 01:00:00  113.824  113.872  113.776  113.866   3990.7600   \n",
      "19127 2022-01-26 02:00:00  113.866  113.894  113.829  113.860   2336.4399   \n",
      "19128 2022-01-26 03:00:00  113.860  113.888  113.854  113.865   2207.1799   \n",
      "19129 2022-01-26 04:00:00  113.867  113.929  113.859  113.920   2006.3600   \n",
      "19130 2022-01-26 05:00:00  113.920  113.920  113.874  113.894   2331.4099   \n",
      "19131 2022-01-26 06:00:00  113.894  113.969  113.870  113.966   2459.2500   \n",
      "19132 2022-01-26 07:00:00  113.967  113.986  113.923  113.984   4136.4102   \n",
      "19133 2022-01-26 08:00:00  113.984  114.152  113.973  114.143   7057.9302   \n",
      "19134 2022-01-26 09:00:00  114.144  114.180  114.073  114.124   5437.1299   \n",
      "19135 2022-01-26 10:00:00  114.125  114.235  114.099  114.162   4252.7598   \n",
      "19136 2022-01-26 11:00:00  114.163  114.197  114.129  114.196   4907.1899   \n",
      "19137 2022-01-26 12:00:00  114.197  114.209  114.154  114.185   4477.0601   \n",
      "19138 2022-01-26 13:00:00  114.183  114.314  114.180  114.304   5867.2100   \n",
      "19139 2022-01-26 14:00:00  114.304  114.362  114.225  114.351   9455.4600   \n",
      "\n",
      "                      time  log_volume  log_volume_scaled  time_group  \\\n",
      "19110  2022-01-25 09:00:00    9.270782           0.302998         164   \n",
      "19111  2022-01-25 10:00:00    8.809040          -0.167944         164   \n",
      "19112  2022-01-25 11:00:00    9.032707           0.060179         164   \n",
      "19113  2022-01-25 12:00:00    8.820757          -0.155994         164   \n",
      "19114  2022-01-25 13:00:00    9.257379           0.289328         164   \n",
      "19115  2022-01-25 14:00:00    9.526709           0.564024         164   \n",
      "19116  2022-01-25 15:00:00    9.794109           0.836751         164   \n",
      "19117  2022-01-25 16:00:00    8.937398          -0.037028         164   \n",
      "19118  2022-01-25 17:00:00    8.196200          -0.792994         164   \n",
      "19119  2022-01-25 18:00:00    8.210263          -0.778651         164   \n",
      "19120  2022-01-25 19:00:00    7.817323          -1.179419         164   \n",
      "19121  2022-01-25 20:00:00    8.165275          -0.824535         164   \n",
      "19122  2022-01-25 21:00:00    7.236102          -1.772221         164   \n",
      "19123  2022-01-25 22:00:00    8.935728          -0.038731         164   \n",
      "19124  2022-01-25 23:00:00    7.948353          -1.045779         164   \n",
      "19125  2022-01-26 00:00:00    8.805706          -0.171344         164   \n",
      "19126  2022-01-26 01:00:00    8.291988          -0.695298         164   \n",
      "19127  2022-01-26 02:00:00    7.756812          -1.241137         164   \n",
      "19128  2022-01-26 03:00:00    7.699924          -1.299158         164   \n",
      "19129  2022-01-26 04:00:00    7.604576          -1.396406         164   \n",
      "19130  2022-01-26 05:00:00    7.754657          -1.243334         164   \n",
      "19131  2022-01-26 06:00:00    7.808018          -1.188910         164   \n",
      "19132  2022-01-26 07:00:00    8.327825          -0.658746         164   \n",
      "19133  2022-01-26 08:00:00    8.862049          -0.113879         164   \n",
      "19134  2022-01-26 09:00:00    8.601191          -0.379935         164   \n",
      "19135  2022-01-26 10:00:00    8.355559          -0.630460         164   \n",
      "19136  2022-01-26 11:00:00    8.498660          -0.484507         164   \n",
      "19137  2022-01-26 12:00:00    8.406945          -0.578050         164   \n",
      "19138  2022-01-26 13:00:00    8.677305          -0.302304         164   \n",
      "19139  2022-01-26 14:00:00    9.154453           0.184351         164   \n",
      "\n",
      "       close_delta  close_return  close_log_return  close_log_return_scaled  \\\n",
      "19110        0.155      0.001361          0.001360                 1.173771   \n",
      "19111        0.054      0.000473          0.000473                 0.404426   \n",
      "19112       -0.102     -0.000894         -0.000894                -0.782362   \n",
      "19113        0.044      0.000386          0.000386                 0.328516   \n",
      "19114       -0.151     -0.001324         -0.001325                -1.155994   \n",
      "19115       -0.022     -0.000193         -0.000193                -0.173957   \n",
      "19116        0.073      0.000641          0.000641                 0.549768   \n",
      "19117       -0.079     -0.000693         -0.000694                -0.608147   \n",
      "19118       -0.029     -0.000255         -0.000255                -0.227354   \n",
      "19119        0.029      0.000255          0.000255                 0.214697   \n",
      "19120        0.050      0.000439          0.000439                 0.374618   \n",
      "19121       -0.020     -0.000176         -0.000176                -0.158687   \n",
      "19122       -0.047     -0.000413         -0.000413                -0.364476   \n",
      "19123       -0.001     -0.000009         -0.000009                -0.013950   \n",
      "19124        0.040      0.000351          0.000351                 0.298490   \n",
      "19125       -0.068     -0.000597         -0.000597                -0.524584   \n",
      "19126        0.042      0.000369          0.000369                 0.313807   \n",
      "19127       -0.006     -0.000053         -0.000053                -0.052055   \n",
      "19128        0.005      0.000044          0.000044                 0.031777   \n",
      "19129        0.055      0.000483          0.000483                 0.412722   \n",
      "19130       -0.026     -0.000228         -0.000228                -0.204400   \n",
      "19131        0.072      0.000632          0.000632                 0.542066   \n",
      "19132        0.018      0.000158          0.000158                 0.130716   \n",
      "19133        0.159      0.001395          0.001394                 1.203291   \n",
      "19134       -0.019     -0.000166         -0.000166                -0.150786   \n",
      "19135        0.038      0.000333          0.000333                 0.282562   \n",
      "19136        0.034      0.000298          0.000298                 0.252071   \n",
      "19137       -0.011     -0.000096         -0.000096                -0.089920   \n",
      "19138        0.119      0.001042          0.001042                 0.897550   \n",
      "19139        0.047      0.000411          0.000411                 0.350406   \n",
      "\n",
      "         ret_mean_5  ret_mean_10  labels  train_label  \n",
      "19110  5.812758e-04     0.000035       1            2  \n",
      "19111  5.388166e-04     0.000097       1            2  \n",
      "19112  2.457542e-04     0.000143       1            2  \n",
      "19113  2.842904e-04     0.000213       1            2  \n",
      "19114  3.122502e-18     0.000108       1            2  \n",
      "19115 -3.106231e-04     0.000135       1            2  \n",
      "19116 -2.771250e-04     0.000131       1            2  \n",
      "19117 -2.369721e-04     0.000004       1            2  \n",
      "19118 -3.650885e-04    -0.000040       1            2  \n",
      "19119 -4.917284e-05    -0.000025       1            2  \n",
      "19120  7.726211e-05    -0.000117       1            2  \n",
      "19121 -8.602188e-05    -0.000182       1            2  \n",
      "19122 -2.986084e-05    -0.000133       1            2  \n",
      "19123  1.932427e-05    -0.000173       1            2  \n",
      "19124  3.863682e-05    -0.000005       1            2  \n",
      "19125 -1.686104e-04    -0.000046       1            2  \n",
      "19126 -5.971040e-05    -0.000073       1            2  \n",
      "19127  1.229618e-05    -0.000009       1            2  \n",
      "19128  2.283536e-05     0.000021       1            2  \n",
      "19129  4.916335e-05     0.000044       1            2  \n",
      "19130  1.229591e-04    -0.000023       1            2  \n",
      "19131  1.755680e-04     0.000058       1            2  \n",
      "19132  2.176928e-04     0.000115       1            2  \n",
      "19133  4.877024e-04     0.000255       1            2  \n",
      "19134  3.578258e-04     0.000203       1            2  \n",
      "19135  4.700602e-04     0.000297       1            2  \n",
      "19136  4.032224e-04     0.000289       1            2  \n",
      "19137  3.523705e-04     0.000285       1            2  \n",
      "19138  2.819035e-04     0.000385       1            2  \n",
      "19139  3.974178e-04     0.000378       1            2  \n",
      "timestamp                  2022-01-26 15:00:00\n",
      "open                                   114.351\n",
      "high                                   114.383\n",
      "low                                    114.217\n",
      "close                                   114.32\n",
      "volume                               9571.8203\n",
      "time                       2022-01-26 15:00:00\n",
      "log_volume                            9.166683\n",
      "log_volume_scaled                     0.196825\n",
      "time_group                                 164\n",
      "close_delta                             -0.031\n",
      "close_return                         -0.000271\n",
      "close_log_return                     -0.000271\n",
      "close_log_return_scaled              -0.241605\n",
      "ret_mean_5                            0.000277\n",
      "ret_mean_10                           0.000373\n",
      "labels                                       1\n",
      "train_label                                  2\n",
      "Name: 19140, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoyo\\miniconda3\\envs\\fxml\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4fb71a3dda14939995913cdfa459148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                                    â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "       Test metric             DataLoader 0\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "        test_acc            0.39674457907676697\n",
      "        test_loss           1.0228668451309204\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.0228668451309204, 'test_acc': 0.39674457907676697}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159383f8-d6f8-4f66-a3a6-925699ed5f19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
